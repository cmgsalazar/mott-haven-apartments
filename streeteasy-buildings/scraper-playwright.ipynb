{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2c0a2b-f1ac-4980-bdfb-1a2350265d55",
   "metadata": {},
   "source": [
    "### StreetEasy Mott Haven Buildings, Attempt 2\n",
    "\n",
    "Previously, we attempted to scrape the [list of buildings in Mott Haven](https://streeteasy.com/buildings/mott-haven) from the StreetEasy website through `BeautifulSoup`. However, the page seems to use JS to dynamically load content. So, we'll try scraping through headless browser `Playwright`.\n",
    "\n",
    "The details we need are the following:\n",
    "\n",
    "* building name\n",
    "* address\n",
    "* coordinates (for mapping)\n",
    "* year it was built\n",
    "* number of stories\n",
    "* number of units\n",
    "* link to individual pages (which we will use to get more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "407f78fb-3421-4035-8047-3c0f722e3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randrange\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f5bb29c-eca3-456b-a300-38b0eca6ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snoozer\n",
    "\n",
    "def snoozer(start_time, end_time):\n",
    "    '''\n",
    "    This function creates a snoozer that can be used when scraping.\n",
    "    It requires `from random import randrange` and `import time`. \n",
    "    \n",
    "    Parameters: \n",
    "    start_time (int) = start time of range, in seconds\n",
    "    end_time (int) = end time of range, in seconds\n",
    "    '''\n",
    "    timer = randrange(start_time, end_time)\n",
    "    print(f\"Snoozing for {timer} seconds...\")\n",
    "    time.sleep(timer)\n",
    "    print(\"\") # adds a line break for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bac985-7f62-4b9e-b507-123d7e9c50ce",
   "metadata": {},
   "source": [
    "### Apparently, it's more convenient to `soup`-ify Playwright `page.content()`\n",
    "\n",
    "This worked... until I was denied access to the webpage. (I used VPN!)\n",
    "\n",
    "As solutions, I found an article about [undetectable](https://scrapingant.com/blog/playwright-scraping-undetectable) `Playwright` and setting up [free proxies](https://free-proxy-list.net)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e16896-53e6-41df-92d7-1eb60eff5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to scrape page 1...\n",
      "Successfuly scraped page 1!\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "Snoozing for 110 seconds...\n",
      "\n",
      "Attempting to scrape page 2...\n",
      "Error 'Page.goto: Target page, context or browser has been closed' was found on https://streeteasy.com/buildings/mott-haven?page=2, page 2 of 2 pages. Moving to next scrape...\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "Done scraping 2 of 2 pages!\n"
     ]
    }
   ],
   "source": [
    "## SOMA VERSION\n",
    "\n",
    "base_url = \"https://streeteasy.com/buildings/mott-haven\"\n",
    "end_page = 2 # number of pages we want to scrape\n",
    "### for now, `end_page` is set to 1... but when this code works, it should be changed back to 45.\n",
    "errors_list = [] # holds pages with errors\n",
    "all_data = [] # holds all captured lists\n",
    "\n",
    "# initializing lists\n",
    "building_names = []\n",
    "building_links = []\n",
    "building_addresses = []\n",
    "building_latlng = []\n",
    "building_year = []\n",
    "building_stories = []\n",
    "building_units = []\n",
    "\n",
    "# starting playwright   \n",
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.firefox.launch(headless=False) # False because I want to see it load the page\n",
    "context = await browser.new_context(user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\")\n",
    "page = await context.new_page()\n",
    "\n",
    "for page_num in range(1, end_page + 1): \n",
    "    print(f\"Attempting to scrape page {page_num}...\")\n",
    "        \n",
    "    try:\n",
    "        ## requesting URLs\n",
    "        if page_num != 1:\n",
    "            url = f\"{base_url}?page={page_num}\"\n",
    "        else:\n",
    "            url = base_url\n",
    "\n",
    "        await page.goto(url, timeout=120000)\n",
    "        \n",
    "        soup = BeautifulSoup(await page.content(), \"html.parser\") # Playwright -> BeautifulSoup is easier?\n",
    "        \n",
    "        # extracting data\n",
    "        target_items = soup.find_all(\"li\", class_=\"item building\")\n",
    "        \n",
    "        building_names = [ target.find(\"h2\", class_=\"details-title\").get_text(strip=True).replace(\"SAVE\", \"\") for target in target_items ]\n",
    "        building_links = [ \"https://streeteasy.com\" + target.find(\"a\").get(\"href\") for target in target_items]\n",
    "        building_latlng = [ target.get(\"se:map:point\") for target in target_items]\n",
    "    \n",
    "        ## other data held separately\n",
    "\n",
    "        for target in target_items:\n",
    "            # initializing placeholder variables\n",
    "            address_tag = target.find(\"ul\").find(\"li\")\n",
    "            if \"At \" in address_tag.get_text():\n",
    "                addresses = address_tag.get_text(strip=True).replace(\"At \", \"\")\n",
    "            else:\n",
    "                addresses = np.nan # this temporarily places NaN, will be replaced if `detail` is found\n",
    "            \n",
    "            other_details = target.find(\"ul\", class_=\"details_info\")\n",
    "            units = stories = year = np.nan # this temporarily places NaN, will be replaced if `detail` is found\n",
    "            \n",
    "            if other_details: \n",
    "                for detail in other_details.find_all(\"li\", class_=\"detail_cell\"):\n",
    "                    text = detail.get_text(strip=True)\n",
    "                    if \"units\" in text:\n",
    "                        units = int(text.split()[0]) \n",
    "                    elif \"stories\" in text:\n",
    "                        stories = int(text.split()[0]) \n",
    "                    elif \"built in\" in text:\n",
    "                        year = int(text.split()[-1]) \n",
    "                        \n",
    "            # appending lists        \n",
    "            building_addresses.append(addresses)\n",
    "            building_units.append(units)\n",
    "            building_stories.append(stories)\n",
    "            building_year.append(year)\n",
    "        \n",
    "        print(f\"Successfuly scraped page {page_num}!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors_list.append(url)\n",
    "        print(f\"Error '{e}' was found on {url}, page {page_num} of {end_page} pages. Moving to next scrape...\")\n",
    "    \n",
    "    finally:\n",
    "        # checking to see if they all have the same range\n",
    "        print(len(building_names))\n",
    "        print(len(building_links))\n",
    "        print(len(building_addresses))\n",
    "        print(len(building_latlng))\n",
    "        print(len(building_year))\n",
    "        print(len(building_stories))\n",
    "        print(len(building_units))\n",
    "\n",
    "        # create df to hold all data\n",
    "        all_data.append(pd.DataFrame({ \"building_name\": building_names,\n",
    "                                     \"link\": building_links,\n",
    "                                     \"address\": building_addresses,\n",
    "                                     \"coordinates\": building_latlng,\n",
    "                                     \"year_built\": building_year,\n",
    "                                     \"total_stories\": building_stories,\n",
    "                                     \"total_units\": building_units\n",
    "                                    }))\n",
    "        \n",
    "        if page_num <= end_page - 1:\n",
    "            snoozer(32, 132)\n",
    "\n",
    "    await browser.close()\n",
    "    \n",
    "print(f\"Done scraping {page_num} of {end_page} pages!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fafd1478-0b30-46c8-b23d-829ee8176d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_name</th>\n",
       "      <th>link</th>\n",
       "      <th>address</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>year_built</th>\n",
       "      <th>total_stories</th>\n",
       "      <th>total_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Arches</td>\n",
       "      <td>https://streeteasy.com/building/the-arches</td>\n",
       "      <td>228 East 135th Street</td>\n",
       "      <td>40.80996311,-73.93100657</td>\n",
       "      <td>2020</td>\n",
       "      <td>25.0</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One38</td>\n",
       "      <td>https://streeteasy.com/building/one38-138-bruc...</td>\n",
       "      <td>138 Bruckner Boulevard</td>\n",
       "      <td>40.80353387,-73.9207622</td>\n",
       "      <td>2024</td>\n",
       "      <td>12.0</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bruckner House</td>\n",
       "      <td>https://streeteasy.com/building/bruckner-house</td>\n",
       "      <td>40 Bruckner Boulevard</td>\n",
       "      <td>40.80629384,-73.92722838</td>\n",
       "      <td>2023</td>\n",
       "      <td>12.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maven Mott Haven</td>\n",
       "      <td>https://streeteasy.com/building/maven-mott-haven</td>\n",
       "      <td>2413 Third Avenue</td>\n",
       "      <td>40.80875296,-73.93145214</td>\n",
       "      <td>2023</td>\n",
       "      <td>27.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Motto</td>\n",
       "      <td>https://streeteasy.com/building/the-motto</td>\n",
       "      <td>2455 Third Avenue</td>\n",
       "      <td>40.8093456,-73.9296974</td>\n",
       "      <td>2023</td>\n",
       "      <td>23.0</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>445 Gerard Avenue</td>\n",
       "      <td>https://streeteasy.com/building/445-gerard-ave...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.81754349,-73.9300955</td>\n",
       "      <td>2023</td>\n",
       "      <td>11.0</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Third at Bankside</td>\n",
       "      <td>https://streeteasy.com/building/third-at-bankside</td>\n",
       "      <td>2401 Third Avenue</td>\n",
       "      <td>40.80867363,-73.9319146</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>101 Bruckner Boulevard</td>\n",
       "      <td>https://streeteasy.com/building/101-bruckner-b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.8054816,-73.925894</td>\n",
       "      <td>2021</td>\n",
       "      <td>7.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lincoln at Bankside</td>\n",
       "      <td>https://streeteasy.com/building/lincoln-at-ban...</td>\n",
       "      <td>5 Lincoln Avenue</td>\n",
       "      <td>40.8071064,-73.9300365</td>\n",
       "      <td>2023</td>\n",
       "      <td>26.0</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>276 Grand Concourse</td>\n",
       "      <td>https://streeteasy.com/building/276-grand-conc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.81388952,-73.92888188</td>\n",
       "      <td>2022</td>\n",
       "      <td>12.0</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Arches</td>\n",
       "      <td>https://streeteasy.com/building/the-arches</td>\n",
       "      <td>228 East 135th Street</td>\n",
       "      <td>40.80996311,-73.93100657</td>\n",
       "      <td>2020</td>\n",
       "      <td>25.0</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>One38</td>\n",
       "      <td>https://streeteasy.com/building/one38-138-bruc...</td>\n",
       "      <td>138 Bruckner Boulevard</td>\n",
       "      <td>40.80353387,-73.9207622</td>\n",
       "      <td>2024</td>\n",
       "      <td>12.0</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bruckner House</td>\n",
       "      <td>https://streeteasy.com/building/bruckner-house</td>\n",
       "      <td>40 Bruckner Boulevard</td>\n",
       "      <td>40.80629384,-73.92722838</td>\n",
       "      <td>2023</td>\n",
       "      <td>12.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Maven Mott Haven</td>\n",
       "      <td>https://streeteasy.com/building/maven-mott-haven</td>\n",
       "      <td>2413 Third Avenue</td>\n",
       "      <td>40.80875296,-73.93145214</td>\n",
       "      <td>2023</td>\n",
       "      <td>27.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Motto</td>\n",
       "      <td>https://streeteasy.com/building/the-motto</td>\n",
       "      <td>2455 Third Avenue</td>\n",
       "      <td>40.8093456,-73.9296974</td>\n",
       "      <td>2023</td>\n",
       "      <td>23.0</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>445 Gerard Avenue</td>\n",
       "      <td>https://streeteasy.com/building/445-gerard-ave...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.81754349,-73.9300955</td>\n",
       "      <td>2023</td>\n",
       "      <td>11.0</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Third at Bankside</td>\n",
       "      <td>https://streeteasy.com/building/third-at-bankside</td>\n",
       "      <td>2401 Third Avenue</td>\n",
       "      <td>40.80867363,-73.9319146</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101 Bruckner Boulevard</td>\n",
       "      <td>https://streeteasy.com/building/101-bruckner-b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.8054816,-73.925894</td>\n",
       "      <td>2021</td>\n",
       "      <td>7.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lincoln at Bankside</td>\n",
       "      <td>https://streeteasy.com/building/lincoln-at-ban...</td>\n",
       "      <td>5 Lincoln Avenue</td>\n",
       "      <td>40.8071064,-73.9300365</td>\n",
       "      <td>2023</td>\n",
       "      <td>26.0</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>276 Grand Concourse</td>\n",
       "      <td>https://streeteasy.com/building/276-grand-conc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.81388952,-73.92888188</td>\n",
       "      <td>2022</td>\n",
       "      <td>12.0</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             building_name                                               link  \\\n",
       "0               The Arches         https://streeteasy.com/building/the-arches   \n",
       "1                    One38  https://streeteasy.com/building/one38-138-bruc...   \n",
       "2           Bruckner House     https://streeteasy.com/building/bruckner-house   \n",
       "3         Maven Mott Haven   https://streeteasy.com/building/maven-mott-haven   \n",
       "4                The Motto          https://streeteasy.com/building/the-motto   \n",
       "5        445 Gerard Avenue  https://streeteasy.com/building/445-gerard-ave...   \n",
       "6        Third at Bankside  https://streeteasy.com/building/third-at-bankside   \n",
       "7   101 Bruckner Boulevard  https://streeteasy.com/building/101-bruckner-b...   \n",
       "8      Lincoln at Bankside  https://streeteasy.com/building/lincoln-at-ban...   \n",
       "9      276 Grand Concourse  https://streeteasy.com/building/276-grand-conc...   \n",
       "10              The Arches         https://streeteasy.com/building/the-arches   \n",
       "11                   One38  https://streeteasy.com/building/one38-138-bruc...   \n",
       "12          Bruckner House     https://streeteasy.com/building/bruckner-house   \n",
       "13        Maven Mott Haven   https://streeteasy.com/building/maven-mott-haven   \n",
       "14               The Motto          https://streeteasy.com/building/the-motto   \n",
       "15       445 Gerard Avenue  https://streeteasy.com/building/445-gerard-ave...   \n",
       "16       Third at Bankside  https://streeteasy.com/building/third-at-bankside   \n",
       "17  101 Bruckner Boulevard  https://streeteasy.com/building/101-bruckner-b...   \n",
       "18     Lincoln at Bankside  https://streeteasy.com/building/lincoln-at-ban...   \n",
       "19     276 Grand Concourse  https://streeteasy.com/building/276-grand-conc...   \n",
       "\n",
       "                   address               coordinates  year_built  \\\n",
       "0    228 East 135th Street  40.80996311,-73.93100657        2020   \n",
       "1   138 Bruckner Boulevard   40.80353387,-73.9207622        2024   \n",
       "2    40 Bruckner Boulevard  40.80629384,-73.92722838        2023   \n",
       "3        2413 Third Avenue  40.80875296,-73.93145214        2023   \n",
       "4        2455 Third Avenue    40.8093456,-73.9296974        2023   \n",
       "5                      NaN   40.81754349,-73.9300955        2023   \n",
       "6        2401 Third Avenue   40.80867363,-73.9319146        2021   \n",
       "7                      NaN     40.8054816,-73.925894        2021   \n",
       "8         5 Lincoln Avenue    40.8071064,-73.9300365        2023   \n",
       "9                      NaN  40.81388952,-73.92888188        2022   \n",
       "10   228 East 135th Street  40.80996311,-73.93100657        2020   \n",
       "11  138 Bruckner Boulevard   40.80353387,-73.9207622        2024   \n",
       "12   40 Bruckner Boulevard  40.80629384,-73.92722838        2023   \n",
       "13       2413 Third Avenue  40.80875296,-73.93145214        2023   \n",
       "14       2455 Third Avenue    40.8093456,-73.9296974        2023   \n",
       "15                     NaN   40.81754349,-73.9300955        2023   \n",
       "16       2401 Third Avenue   40.80867363,-73.9319146        2021   \n",
       "17                     NaN     40.8054816,-73.925894        2021   \n",
       "18        5 Lincoln Avenue    40.8071064,-73.9300365        2023   \n",
       "19                     NaN  40.81388952,-73.92888188        2022   \n",
       "\n",
       "    total_stories  total_units  \n",
       "0            25.0          156  \n",
       "1            12.0          447  \n",
       "2            12.0          365  \n",
       "3            27.0          200  \n",
       "4            23.0          264  \n",
       "5            11.0          338  \n",
       "6             NaN          458  \n",
       "7             7.0           55  \n",
       "8            26.0          481  \n",
       "9            12.0          215  \n",
       "10           25.0          156  \n",
       "11           12.0          447  \n",
       "12           12.0          365  \n",
       "13           27.0          200  \n",
       "14           23.0          264  \n",
       "15           11.0          338  \n",
       "16            NaN          458  \n",
       "17            7.0           55  \n",
       "18           26.0          481  \n",
       "19           12.0          215  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting this to our final df\n",
    "\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23949956-2140-4959-a9e7-3b226fed65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the file to csv\n",
    "\n",
    "final_df.to_csv(\"mott-haven-streeteasy-buildings.csv\", encoding=\"UTF-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf4a4c-71dc-46bc-9e2b-1435c8be25a3",
   "metadata": {},
   "source": [
    "#### ^ The above blocks of code worked when I scraped the first page of [Port Morris](https://streeteasy.com/buildings/mott-haven), but I'm getting `access denied` when trying Mott Haven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f288d86-587a-4453-b7f0-fbf880c97427",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0ba58b-2264-4b44-91e6-46bf3c6b2490",
   "metadata": {},
   "source": [
    "### This was the original Playwright code I've been working on... \n",
    "\n",
    "A recurring problem is access check-ins then denials when we try to jump to the next page. I haven't run the scrapers yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e4451-5ae5-4682-9e78-b1d3cc464348",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAIN CODE\n",
    "# this is tweaked from the bs4 scraper version\n",
    "\n",
    "base_url = \"https://streeteasy.com/buildings/mott-haven\"\n",
    "end_page = 2 # number of pages we want to scrape\n",
    "### for now, `end_page` is set to 2... but when this code works, it should be changed back to 45.\n",
    "errors_list = [] # holds pages with errors\n",
    "main_df = [] # holds all captured lists\n",
    "\n",
    "# starting playwright\n",
    "async def scraper():\n",
    "    '''\n",
    "    This function scrapes a page asynchronously.\n",
    "    '''\n",
    "    async with async_playwright() as playwright:\n",
    "        browser = await playwright.firefox.launch(headless=False) # False because I want to see it load the page\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "    \n",
    "        try:\n",
    "            for page_num in range(1, end_page + 1):\n",
    "                print(f\"Attempting to scrape page {page_num}...\")\n",
    "                \n",
    "                ## requesting URLs\n",
    "                if page_num != 1:\n",
    "                    url = f\"{base_url}?page={page_num}\"\n",
    "                else:\n",
    "                    url = base_url\n",
    "                await page.goto(url)\n",
    "                await page.wait_for_load_state('networkidle')\n",
    "        \n",
    "                ## extracting data\n",
    "                # target_items = await page.query_selector_all(\"li.item.building\")\n",
    "            \n",
    "                # building_names = [ await target.query_selector(\"h2.details-title\").inner_text() for target in target_items ]\n",
    "                # building_links = [ \"https://streeteasy.com\" + await query_selector(\"a\").get_attribute(\"href\") for target in target_items]\n",
    "                # building_addresses = [ await target.query_selector(\"ul li\").inner_text() for target in target_items ]\n",
    "                # building_latlng = [ await target.get_attribute(\"se:map:point\") for target in target_items]\n",
    "            \n",
    "                # ## other data held separately\n",
    "                # for target in target_items:        \n",
    "                #     other_details = await target.query_selector(\"ul.details_info li.detail_cell\")        \n",
    "                #     building_units = [ await other_details[0].inner_text().replace(\" units\", \"\").strip() ]\n",
    "                #     building_stories = [ await other_details[1].inner_text().replace(\" stories\", \"\").strip() ]\n",
    "                #     building_year = [ await other_details[2].inner_text().replace(\"built in\", \"\").strip() ]\n",
    "    \n",
    "                print(f\"Successfuly scraped page {page_num}!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            errors_list.append(url)\n",
    "            print(f\"Error '{e}' was found on {url}, page {page_num} of {end_page} pages. Moving to next scrape...\")\n",
    "            \n",
    "        finally:\n",
    "            # ## create df to hold all data\n",
    "            # main_df.append(pd.DataFrame({ \"building_name\": building_names,\n",
    "                                         # \"link\": building_links,\n",
    "                                         # \"address\": building_addresses,\n",
    "                                         # \"coordinates\": building_latlng,\n",
    "                                         # \"year_built\": building_year,\n",
    "                                         # \"total_stories\": building_stories,\n",
    "                                         # \"total_units\": building_units\n",
    "                                        # }))\n",
    "            \n",
    "            snoozer(21, 56)\n",
    "    \n",
    "            # closing playwright\n",
    "            await browser.close()\n",
    "            print(f\"Done scraping {end_page} pages!\") \n",
    "\n",
    "nest_asyncio.apply()\n",
    "asyncio.run(scraper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006f244-666a-49e4-be02-ec3fb7f158c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
